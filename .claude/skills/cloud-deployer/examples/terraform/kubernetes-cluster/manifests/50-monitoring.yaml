# =============================================================================
# Prometheus Deployment
# =============================================================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
        - name: prometheus
          image: prom/prometheus:latest
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
          ports:
            - name: web
              containerPort: 9090
              protocol: TCP
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: storage
              mountPath: /prometheus
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: storage
          emptyDir: {}

---

# =============================================================================
# Prometheus Service
# =============================================================================

apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  type: ClusterIP
  ports:
    - name: web
      port: 9090
      targetPort: 9090
      protocol: TCP
  selector:
    app: prometheus

---

# =============================================================================
# Prometheus Service Account
# =============================================================================

apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring

---

# =============================================================================
# Prometheus ClusterRole
# =============================================================================

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups:
      - extensions
      - networking.k8s.io
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]

---

# =============================================================================
# Prometheus ClusterRoleBinding
# =============================================================================

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring

---

# =============================================================================
# Grafana Deployment
# =============================================================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      serviceAccountName: grafana
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      containers:
        - name: grafana
          image: grafana/grafana:latest
          ports:
            - name: web
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_PASSWORD
              value: "admin"  # Change in production!
            - name: GF_INSTALL_PLUGINS
              value: ""
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "200m"
          volumeMounts:
            - name: data
              mountPath: /var/lib/grafana
            - name: provisioning
              mountPath: /etc/grafana/provisioning
      volumes:
        - name: data
          emptyDir: {}
        - name: provisioning
          emptyDir: {}

---

# =============================================================================
# Grafana Service
# =============================================================================

apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  type: ClusterIP
  ports:
    - name: web
      port: 3000
      targetPort: 3000
      protocol: TCP
  selector:
    app: grafana

---

# =============================================================================
# Grafana Service Account
# =============================================================================

apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana
  namespace: monitoring

---

# =============================================================================
# ServiceMonitor for Backend (Prometheus Operator)
# =============================================================================

# Note: This requires Prometheus Operator to be installed
# Install with: helm install prometheus-operator prometheus-community/kube-prometheus-stack

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backend-monitor
  namespace: todo-app
  labels:
    app: backend
spec:
  selector:
    matchLabels:
      app: backend
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s

---

# =============================================================================
# Pod Monitor for Backend (Alternative to ServiceMonitor)
# =============================================================================

apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: backend-pods
  namespace: todo-app
  labels:
    app: backend
spec:
  selector:
    matchLabels:
      app: backend
  podMetricsEndpoints:
    - port: http
      path: /metrics
      interval: 15s

---

# =============================================================================
# Prometheus Rules for Alerting
# =============================================================================

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
  namespace: monitoring
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    - name: application.rules
      rules:
        - alert: HighErrorRate
          expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "High error rate detected"
            description: "Error rate is {{ $value }} errors/sec"

        - alert: HighLatency
          expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High latency detected"
            description: "P95 latency is {{ $value }} seconds"

        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Pod is crash looping"
            description: "{{ $labels.pod }} is restarting frequently"

        - alert: HighMemoryUsage
          expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage"
            description: "Container {{ $labels.container }} is using >90% of memory limit"

        - alert: DatabaseConnectionPoolExhausted
          expr: db_pool_active_connections / db_pool_max_connections > 0.9
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Database connection pool nearly exhausted"
            description: "Pool is {{ $value }}% full"

---

# =============================================================================
# Dashboard ConfigMap (Grafana)
# =============================================================================

apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  app-dashboard.json: |
    {
      "dashboard": {
        "title": "Application Metrics",
        "panels": [
          {
            "title": "Request Rate",
            "targets": [
              {
                "expr": "rate(http_requests_total[5m])"
              }
            ]
          },
          {
            "title": "Error Rate",
            "targets": [
              {
                "expr": "rate(http_requests_total{status=~\"5..\"}[5m])"
              }
            ]
          },
          {
            "title": "P95 Latency",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
              }
            ]
          }
        ]
      }
    }
